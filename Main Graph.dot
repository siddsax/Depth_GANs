digraph G {
	graph [bb="0,0,1336,9644"];
	node [label="\N",
		shape=oval
	];
	n1	 [height=1.6303,
		label="Node1\ninput = {torch.CudaTensor[1x3x256x256]}\lmodule = cudnn.Tanh\lreverseMap = {}\lgradOutput = {torch.CudaTensor[1x3x256x256]}",
		pos="780,191",
		tooltip="[[C]]:-1_",
		width=5.6479];
	n2	 [height=1.3356,
		label="Node2\ninput = {torch.CudaTensor[1x3x256x256]}\lreverseMap = {}\lgradOutput = {torch.CudaTensor[1x3x256x256]}",
		pos="780,48",
		tooltip="[[C]]:-1_",
		width=5.6479];
	n1 -> n2	 [pos="e,780,96.121 780,132.24 780,123.7 780,114.9 780,106.36"];
	n3	 [height=1.9249,
		label="Node3\ninput = {torch.CudaTensor[1x3x256x256],torch.CudaTensor[1x3x256x256]}\lmapindex = {Node4,Node5}\lmodule = nn.CAddTable\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x3x256x256]}",
		pos="780,356",
		tooltip="[[C]]:-1_",
		width=8.6169];
	n3 -> n1	 [pos="e,780,249.75 780,286.35 780,277.59 780,268.63 780,259.89"];
	n4	 [height=1.6303,
		label="Node4\ninput = {torch.CudaTensor[1x128x128x128]}\lmodule = cudnn.SpatialFullConvolution(128 -> 3, 4x4, 2,2, 1,1)\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x3x256x256]}",
		pos="594,521",
		tooltip="[[C]]:-1_",
		width=7.2825];
	n4 -> n3	 [pos="e,704.33,423.31 658.01,463.9 670.48,452.97 683.73,441.36 696.72,429.98"];
	n5	 [height=1.6303,
		label="Node5\ninput = {torch.CudaTensor[1x64x128x128]}\lmodule = cudnn.SpatialFullConvolution(64 -> 3, 4x4, 2,2, 1,1)\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x3x256x256]}",
		pos="1049,5757",
		tooltip="[[C]]:-1_",
		width=7.1443];
	n5 -> n3	 [pos="e,847.78,423.65 1024,5698.6 999.84,5638 967,5539.1 967,5450 967,5450 967,5450 967,674 967,581.01 906.57,491.31 854.42,431.2"];
	n6	 [height=1.6303,
		label="Node6\ninput = {torch.CudaTensor[1x128x128x128]}\lmodule = cudnn.ReLU\lreverseMap = {}\lgradOutput = {torch.CudaTensor[1x128x128x128]}",
		pos="427,675",
		tooltip="[[C]]:-1_",
		width=5.9243];
	n6 -> n4	 [pos="e,532.16,578.28 487.76,618.69 499.73,607.8 512.38,596.29 524.61,585.16"];
	n7	 [height=1.6303,
		label="Node7\ninput = {torch.CudaTensor[1x64x128x128]}\lmodule = nn.LeakyReLU(0.2)\lreverseMap = {}\lgradOutput = {torch.CudaTensor[1x64x128x128]}",
		pos="1073,6065",
		tooltip="[[C]]:-1_",
		width=5.7861];
	n7 -> n5	 [pos="e,1053.5,5815.9 1068.5,6006.1 1064.4,5954.9 1058.6,5880.2 1054.3,5826.1"];
	n8	 [height=1.9249,
		label="Node8\ninput = {torch.CudaTensor[1x64x128x128],torch.CudaTensor[1x64x128x128]}\lmapindex = {Node10,Node11}\lmodule = nn.JoinTable\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x128x128x128]}",
		pos="341,840",
		tooltip="[[C]]:-1_",
		width=8.8696];
	n8 -> n6	 [pos="e,396.76,733.32 376.97,770.82 381.96,761.36 387.08,751.66 392.05,742.25"];
	n9	 [height=1.6303,
		label="Node9\ninput = {torch.CudaTensor[1x64x128x128]}\lmodule = cudnn.SpatialBatchNormalization\lreverseMap = {}\lgradOutput = {torch.CudaTensor[\
1x64x128x128]}",
		pos="1075,6230",
		tooltip="[[C]]:-1_",
		width=5.7861];
	n9 -> n7	 [pos="e,1073.7,6123.7 1074.3,6171.1 1074.1,6159.1 1074,6146.3 1073.8,6134"];
	n10	 [height=1.6303,
		label="Node10\ninput = {torch.CudaTensor[1x64x128x128]}\lmodule = cudnn.SpatialBatchNormalization\lreverseMap = {}\lgradOutput = {torch.CudaTensor[\
1x64x128x128]}",
		pos="341,1005",
		tooltip="[[C]]:-1_",
		width=5.7861];
	n10 -> n8	 [pos="e,341,909.33 341,946.07 341,937.43 341,928.4 341,919.42"];
	n11	 [height=1.9249,
		label="Node11\ngradOutputBuffer = torch.CudaTensor[1x64x128x128]\linput = {torch.CudaTensor[1x3x256x256]}\lmodule = cudnn.SpatialConvolution(\
3 -> 64, 4x4, 2,2, 1,1)\lreverseMap = {}\lgradOutput = {torch.CudaTensor[1x64x128x128],torch.CudaTensor[1x64x128x128]}",
		pos="362,9134",
		tooltip="[[C]]:-1_",
		width=9.5369];
	n11 -> n8	 [pos="e,186.68,900.81 211.89,9071.7 112.36,9019.9 0,8935.1 0,8816 0,8816 0,8816 0,1158 0,1049.1 43.07,1020 123,946 139.31,930.9 158.19,\
917.55 177.89,905.88"];
	n29	 [height=1.6303,
		label="Node29\ninput = {torch.CudaTensor[1x64x128x128]}\lmodule = nn.LeakyReLU(0.2)\lreverseMap = {}\lgradOutput = {torch.CudaTensor[1x64x128x128]}",
		pos="362,8969",
		tooltip="[[C]]:-1_",
		width=5.7861];
	n11 -> n29	 [pos="e,362,9027.8 362,9064.3 362,9055.6 362,9046.6 362,9037.9"];
	n12	 [height=1.6303,
		label="Node12\ninput = {torch.CudaTensor[1x128x64x64]}\lmodule = cudnn.SpatialFullConvolution(128 -> 64, 4x4, 2,2, 1,1)\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x64x128x128]}",
		pos="1069,6395",
		tooltip="[[C]]:-1_",
		width=7.3969];
	n12 -> n9	 [pos="e,1072.9,6288.7 1071.1,6336.1 1071.6,6324.1 1072,6311.3 1072.5,6299"];
	n13	 [height=1.6303,
		label="Node13\ninput = {torch.CudaTensor[1x256x64x64]}\lmodule = cudnn.SpatialFullConvolution(256 -> 64, 4x4, 2,2, 1,1)\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x64x128x128]}",
		pos="341,1159",
		tooltip="[[C]]:-1_",
		width=7.3969];
	n13 -> n10	 [pos="e,341,1063.7 341,1100.1 341,1091.5 341,1082.7 341,1073.9"];
	n14	 [height=1.6303,
		label="Node14\ninput = {{torch.CudaTensor[1x1x1x1],torch.CudaTensor[1x3x256x256]}}\lreverseMap = {}\lselectindex = 2\lgradOutput = {torch.CudaTensor[\
1x3x256x256]}",
		pos="363,9299",
		tooltip="[[C]]:-1_-2",
		width=8.3406];
	n14 -> n11	 [pos="e,362.42,9203.3 362.64,9240.1 362.59,9231.4 362.54,9222.4 362.48,9213.4"];
	n15	 [height=1.6303,
		label="Node15\ninput = {torch.CudaTensor[1x128x64x64]}\lmodule = nn.LeakyReLU(0.2)\lreverseMap = {}\lgradOutput = {torch.CudaTensor[1x128x64x64]}",
		pos="1044,6549",
		tooltip="[[C]]:-1_",
		width=5.6479];
	n15 -> n12	 [pos="e,1059.5,6453.7 1053.5,6490.1 1054.9,6481.4 1056.4,6472.5 1057.9,6463.6"];
	n16	 [height=1.6303,
		label="Node16\ninput = {torch.CudaTensor[1x256x64x64]}\lmodule = cudnn.ReLU\lreverseMap = {}\lgradOutput = {torch.CudaTensor[1x256x64x64]}",
		pos="341,1313",
		tooltip="[[C]]:-1_",
		width=5.6479];
	n16 -> n13	 [pos="e,341,1217.7 341,1254.1 341,1245.5 341,1236.7 341,1227.9"];
	n17	 [height=1.6303,
		label="Node17\ninput = {{torch.CudaTensor[1x1x1x1],torch.CudaTensor[1x3x256x256]}}\lreverseMap = {}\lnSplitOutputs = 2\lgradOutput = {{\
torch.CudaTensor[1x1x1x1],torch.CudaTensor[1x3x256x256]}}",
		pos="672,9453",
		tooltip="[[C]]:-1_ split at [...ddhartha/torch/install/share/lua/5.1/nngraph/gmodule.lua]:96-mnode",
		width=9.0078];
	n17 -> n14	 [pos="e,472.17,9353.7 561.75,9397.8 535.71,9385 507.83,9371.2 481.43,9358.3"];
	n63	 [height=1.6303,
		label="Node63\ninput = {{torch.CudaTensor[1x1x1x1],torch.CudaTensor[1x3x256x256]}}\lreverseMap = {}\lselectindex = 1\lgradOutput = {torch.CudaTensor[\
1x1x1x1]}",
		pos="982,9299",
		tooltip="[[C]]:-1_-1",
		width=8.3406];
	n17 -> n63	 [pos="e,872.48,9353.7 782.6,9397.8 808.74,9385 836.71,9371.2 863.18,9358.3"];
	n18	 [height=1.6303,
		label="Node18\ninput = {torch.CudaTensor[1x128x64x64]}\lmodule = cudnn.SpatialBatchNormalization\lreverseMap = {}\lgradOutput = {torch.CudaTensor[\
1x128x64x64]}",
		pos="1034,6714",
		tooltip="[[C]]:-1_",
		width=5.6479];
	n18 -> n15	 [pos="e,1040.5,6607.7 1037.6,6655.1 1038.3,6643.1 1039.1,6630.3 1039.8,6618"];
	n19	 [height=1.9249,
		label="Node19\ninput = {torch.CudaTensor[1x128x64x64],torch.CudaTensor[1x128x64x64]}\lmapindex = {Node22,Node23}\lmodule = nn.JoinTable\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x256x64x64]}",
		pos="341,1478",
		tooltip="[[C]]:-1_",
		width=8.6169];
	n19 -> n16	 [pos="e,341,1371.8 341,1408.3 341,1399.6 341,1390.6 341,1381.9"];
	n20	 [height=1.3356,
		label="Node20\ninput = {torch.CudaTensor[1x1x1x1],torch.CudaTensor[1x3x256x256]}\lreverseMap = {}\lgradOutput = {{torch.CudaTensor[1x1x1x1],\
torch.CudaTensor[1x3x256x256]}}",
		pos="672,9596",
		tooltip="[[C]]:-1_",
		width=9.0078];
	n20 -> n17	 [pos="e,672,9511.7 672,9547.7 672,9539.4 672,9530.6 672,9521.9"];
	n21	 [height=1.6303,
		label="Node21\ninput = {torch.CudaTensor[1x256x32x32]}\lmodule = cudnn.SpatialFullConvolution(256 -> 128, 4x4, 2,2, 1,1)\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x128x64x64]}",
		pos="1028,6879",
		tooltip="[[C]]:-1_",
		width=7.5351];
	n21 -> n18	 [pos="e,1031.9,6772.7 1030.1,6820.1 1030.6,6808.1 1031,6795.3 1031.5,6783"];
	n22	 [height=1.6303,
		label="Node22\ninput = {torch.CudaTensor[1x128x64x64]}\lmodule = cudnn.SpatialBatchNormalization\lreverseMap = {}\lgradOutput = {torch.CudaTensor[\
1x128x64x64]}",
		pos="346,1643",
		tooltip="[[C]]:-1_",
		width=5.6479];
	n22 -> n19	 [pos="e,343.1,1547.3 344.22,1584.1 343.96,1575.4 343.68,1566.4 343.41,1557.4"];
	n23	 [height=1.9249,
		label="Node23\ngradOutputBuffer = torch.CudaTensor[1x128x64x64]\linput = {torch.CudaTensor[1x128x64x64]}\lmodule = cudnn.SpatialBatchNormalization\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x128x64x64],torch.CudaTensor[1x128x64x64]}",
		pos="362,8650",
		tooltip="[[C]]:-1_",
		width=9.2842];
	n23 -> n19	 [pos="e,191.13,1538.7 216.41,8587.6 195.42,8575 175.16,8560.5 158,8544 79.936,8469 38,8440.3 38,8332 38,8332 38,8332 38,1796 38,1692.8 \
61.697,1658.7 133,1584 147.34,1569 164.3,1555.8 182.25,1544.2"];
	n40	 [height=1.6303,
		label="Node40\ninput = {torch.CudaTensor[1x128x64x64]}\lmodule = nn.LeakyReLU(0.2)\lreverseMap = {}\lgradOutput = {torch.CudaTensor[1x128x64x64]}",
		pos="371,8485",
		tooltip="[[C]]:-1_",
		width=5.6479];
	n23 -> n40	 [pos="e,367.81,8543.8 365.79,8580.3 366.27,8571.6 366.77,8562.6 367.25,8553.9"];
	n24	 [height=1.6303,
		label="Node24\ninput = {torch.CudaTensor[1x256x32x32]}\lmodule = nn.LeakyReLU(0.2)\lreverseMap = {}\lgradOutput = {torch.CudaTensor[1x256x32x32]}",
		pos="1009,7033",
		tooltip="[[C]]:-1_",
		width=5.6479];
	n24 -> n21	 [pos="e,1020.8,6937.7 1016.2,6974.1 1017.3,6965.5 1018.4,6956.7 1019.5,6947.9"];
	n25	 [height=1.6303,
		label="Node25\ninput = {torch.CudaTensor[1x512x32x32]}\lmodule = cudnn.SpatialFullConvolution(512 -> 128, 4x4, 2,2, 1,1)\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x128x64x64]}",
		pos="365,1797",
		tooltip="[[C]]:-1_",
		width=7.5351];
	n25 -> n22	 [pos="e,353.22,1701.7 357.76,1738.1 356.69,1729.5 355.58,1720.7 354.49,1711.9"];
	n26	 [height=1.6303,
		label="Node26\ninput = {torch.CudaTensor[1x64x128x128]}\lmodule = cudnn.SpatialConvolution(64 -> 128, 4x4, 2,2, 1,1)\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x128x64x64]}",
		pos="362,8815",
		tooltip="[[C]]:-1_",
		width=6.9824];
	n26 -> n23	 [pos="e,362,8719.3 362,8756.1 362,8747.4 362,8738.4 362,8729.4"];
	n27	 [height=1.6303,
		label="Node27\ninput = {torch.CudaTensor[1x256x32x32]}\lmodule = cudnn.SpatialBatchNormalization\lreverseMap = {}\lgradOutput = {torch.CudaTensor[\
1x256x32x32]}",
		pos="1002,7198",
		tooltip="[[C]]:-1_",
		width=5.6479];
	n27 -> n24	 [pos="e,1006.5,7091.7 1004.5,7139.1 1005,7127.1 1005.6,7114.3 1006.1,7102"];
	n28	 [height=1.6303,
		label="Node28\ninput = {torch.CudaTensor[1x512x32x32]}\lmodule = cudnn.ReLU\lreverseMap = {}\lgradOutput = {torch.CudaTensor[1x512x32x32]}",
		pos="374,1951",
		tooltip="[[C]]:-1_",
		width=5.6479];
	n28 -> n25	 [pos="e,368.42,1855.7 370.57,1892.1 370.06,1883.5 369.54,1874.7 369.02,1865.9"];
	n29 -> n26	 [pos="e,362,8873.7 362,8910.1 362,8901.5 362,8892.7 362,8883.9"];
	n30	 [height=1.6303,
		label="Node30\ninput = {torch.CudaTensor[1x512x16x16]}\lmodule = cudnn.SpatialFullConvolution(512 -> 256, 4x4, 2,2, 1,1)\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x256x32x32]}",
		pos="1000,7363",
		tooltip="[[C]]:-1_",
		width=7.5351];
	n30 -> n27	 [pos="e,1001.3,7256.7 1000.7,7304.1 1000.9,7292.1 1001,7279.3 1001.2,7267"];
	n31	 [height=1.9249,
		label="Node31\ninput = {torch.CudaTensor[1x256x32x32],torch.CudaTensor[1x256x32x32]}\lmapindex = {Node33,Node34}\lmodule = nn.JoinTable\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x512x32x32]}",
		pos="376,2116",
		tooltip="[[C]]:-1_",
		width=8.6169];
	n31 -> n28	 [pos="e,374.71,2009.8 375.16,2046.3 375.05,2037.6 374.94,2028.6 374.83,2019.9"];
	n32	 [height=1.6303,
		label="Node32\ninput = {torch.CudaTensor[1x512x16x16]}\lmodule = nn.LeakyReLU(0.2)\lreverseMap = {}\lgradOutput = {torch.CudaTensor[1x512x16x16]}",
		pos="999,7517",
		tooltip="[[C]]:-1_",
		width=5.6479];
	n32 -> n30	 [pos="e,999.62,7421.7 999.38,7458.1 999.44,7449.5 999.5,7440.7 999.55,7431.9"];
	n33	 [height=1.6303,
		label="Node33\ninput = {torch.CudaTensor[1x256x32x32]}\lmodule = cudnn.SpatialBatchNormalization\lreverseMap = {}\lgradOutput = {torch.CudaTensor[\
1x256x32x32]}",
		pos="386,2281",
		tooltip="[[C]]:-1_",
		width=5.6479];
	n33 -> n31	 [pos="e,380.19,2185.3 382.45,2222.1 381.92,2213.4 381.36,2204.4 380.81,2195.4"];
	n34	 [height=1.9249,
		label="Node34\ngradOutputBuffer = torch.CudaTensor[1x256x32x32]\linput = {torch.CudaTensor[1x256x32x32]}\lmodule = cudnn.SpatialBatchNormalization\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x256x32x32],torch.CudaTensor[1x256x32x32]}",
		pos="400,8166",
		tooltip="[[C]]:-1_",
		width=9.2842];
	n34 -> n31	 [pos="e,229.85,2177.3 262.05,8102.8 241.67,8090.3 221.88,8076 205,8060 124.98,7984.1 76,7958.3 76,7848 76,7848 76,7848 76,2434 76,2330.4 \
101.52,2297 173,2222 187.05,2207.3 203.64,2194.2 221.17,2182.7"];
	n51	 [height=1.6303,
		label="Node51\ninput = {torch.CudaTensor[1x256x32x32]}\lmodule = nn.LeakyReLU(0.2)\lreverseMap = {}\lgradOutput = {torch.CudaTensor[1x256x32x32]}",
		pos="418,8001",
		tooltip="[[C]]:-1_",
		width=5.6479];
	n34 -> n51	 [pos="e,411.62,8059.8 407.58,8096.3 408.55,8087.6 409.54,8078.6 410.5,8069.9"];
	n35	 [height=1.6303,
		label="Node35\ninput = {torch.CudaTensor[1x512x16x16]}\lmodule = cudnn.SpatialBatchNormalization\lreverseMap = {}\lgradOutput = {torch.CudaTensor[\
1x512x16x16]}",
		pos="998,7682",
		tooltip="[[C]]:-1_",
		width=5.6479];
	n35 -> n32	 [pos="e,998.65,7575.7 998.36,7623.1 998.43,7611.1 998.51,7598.3 998.58,7586"];
	n36	 [height=1.6303,
		label="Node36\ninput = {torch.CudaTensor[1x1024x16x16]}\lmodule = cudnn.SpatialFullConvolution(1024 -> 256, 4x4, 2,2, 1,1)\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x256x32x32]}",
		pos="392,2435",
		tooltip="[[C]]:-1_",
		width=7.6733];
	n36 -> n33	 [pos="e,388.28,2339.7 389.71,2376.1 389.38,2367.5 389.03,2358.7 388.68,2349.9"];
	n37	 [height=1.6303,
		label="Node37\ninput = {torch.CudaTensor[1x128x64x64]}\lmodule = cudnn.SpatialConvolution(128 -> 256, 4x4, 2,2, 1,1)\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x256x32x32]}",
		pos="381,8331",
		tooltip="[[C]]:-1_",
		width=7.0968];
	n37 -> n34	 [pos="e,392.04,8235.3 387.75,8272.1 388.76,8263.4 389.81,8254.4 390.86,8245.4"];
	n38	 [height=1.6303,
		label="Node38\ninput = {torch.CudaTensor[1x256x8x8]}\lmodule = cudnn.SpatialFullConvolution(256 -> 512, 4x4, 2,2, 1,1)\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x512x16x16]}",
		pos="983,7847",
		tooltip="[[C]]:-1_",
		width=7.5351];
	n38 -> n35	 [pos="e,992.69,7740.7 988.33,7788.1 989.44,7776.1 990.61,7763.3 991.74,7751"];
	n39	 [height=1.6303,
		label="Node39\ninput = {torch.CudaTensor[1x1024x16x16]}\lmodule = cudnn.ReLU\lreverseMap = {}\lgradOutput = {torch.CudaTensor[1x1024x16x16]}",
		pos="409,2589",
		tooltip="[[C]]:-1_",
		width=5.7861];
	n39 -> n36	 [pos="e,398.46,2493.7 402.52,2530.1 401.57,2521.5 400.57,2512.7 399.59,2503.9"];
	n40 -> n37	 [pos="e,377.2,8389.7 374.81,8426.1 375.37,8417.5 375.96,8408.7 376.53,8399.9"];
	n41	 [height=1.6303,
		label="Node41\ninput = {torch.CudaTensor[1x256x8x8]}\lmodule = nn.LeakyReLU(0.2)\lreverseMap = {}\lgradOutput = {torch.CudaTensor[1x256x8x8]}",
		pos="983,8001",
		tooltip="[[C]]:-1_",
		width=5.3952];
	n41 -> n38	 [pos="e,983,7905.7 983,7942.1 983,7933.5 983,7924.7 983,7915.9"];
	n42	 [height=1.9249,
		label="Node42\ninput = {torch.CudaTensor[1x512x16x16],torch.CudaTensor[1x512x16x16]}\lmapindex = {Node44,Node45}\lmodule = nn.JoinTable\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x1024x16x16]}",
		pos="414,2754",
		tooltip="[[C]]:-1_",
		width=8.6169];
	n42 -> n39	 [pos="e,410.77,2647.8 411.89,2684.3 411.63,2675.6 411.35,2666.6 411.08,2657.9"];
	n43	 [height=1.6303,
		label="Node43\ninput = {torch.CudaTensor[1x256x8x8]}\lmodule = cudnn.SpatialBatchNormalization\lreverseMap = {}\lgradOutput = {torch.CudaTensor[\
1x256x8x8]}",
		pos="983,8166",
		tooltip="[[C]]:-1_",
		width=5.3952];
	n43 -> n41	 [pos="e,983,8059.7 983,8107.1 983,8095.1 983,8082.3 983,8070"];
	n44	 [height=1.6303,
		label="Node44\ninput = {torch.CudaTensor[1x512x16x16]}\lmodule = cudnn.SpatialBatchNormalization\lreverseMap = {}\lgradOutput = {torch.CudaTensor[\
1x512x16x16]}",
		pos="418,2919",
		tooltip="[[C]]:-1_",
		width=5.6479];
	n44 -> n42	 [pos="e,415.68,2823.3 416.58,2860.1 416.37,2851.4 416.14,2842.4 415.92,2833.4"];
	n45	 [height=1.9249,
		label="Node45\ngradOutputBuffer = torch.CudaTensor[1x512x16x16]\linput = {torch.CudaTensor[1x512x16x16]}\lmodule = cudnn.SpatialBatchNormalization\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x512x16x16],torch.CudaTensor[1x512x16x16]}",
		pos="438,7682",
		tooltip="[[C]]:-1_",
		width=9.2842];
	n45 -> n42	 [pos="e,263.06,2814.7 291.37,7619.5 270.39,7607 250.14,7592.5 233,7576 155.15,7501.1 114,7472.1 114,7364 114,7364 114,7364 114,3072 114,\
3032.2 149.71,2918.1 205,2860 219.31,2845 236.24,2831.7 254.18,2820.2"];
	n62	 [height=1.6303,
		label="Node62\ninput = {torch.CudaTensor[1x512x16x16]}\lmodule = nn.LeakyReLU(0.2)\lreverseMap = {}\lgradOutput = {torch.CudaTensor[1x512x16x16]}",
		pos="446,7517",
		tooltip="[[C]]:-1_",
		width=5.6479];
	n45 -> n62	 [pos="e,443.17,7575.8 441.37,7612.3 441.8,7603.6 442.24,7594.6 442.67,7585.9"];
	n46	 [height=1.6303,
		label="Node46\ninput = {torch.CudaTensor[1x128x4x4]}\lmodule = cudnn.SpatialFullConvolution(128 -> 256, 4x4, 2,2, 1,1)\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x256x8x8]}",
		pos="983,8331",
		tooltip="[[C]]:-1_",
		width=7.5351];
	n46 -> n43	 [pos="e,983,8224.7 983,8272.1 983,8260.1 983,8247.3 983,8235"];
	n47	 [height=1.6303,
		label="Node47\ninput = {torch.CudaTensor[1x1024x8x8]}\lmodule = cudnn.SpatialFullConvolution(1024 -> 512, 4x4, 2,2, 1,1)\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x512x16x16]}",
		pos="422,3073",
		tooltip="[[C]]:-1_",
		width=7.6733];
	n47 -> n44	 [pos="e,419.52,2977.7 420.48,3014.1 420.25,3005.5 420.02,2996.7 419.79,2987.9"];
	n48	 [height=1.6303,
		label="Node48\ninput = {torch.CudaTensor[1x256x32x32]}\lmodule = cudnn.SpatialConvolution(256 -> 512, 4x4, 2,2, 1,1)\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x512x16x16]}",
		pos="428,7847",
		tooltip="[[C]]:-1_",
		width=7.0968];
	n48 -> n45	 [pos="e,433.81,7751.3 431.55,7788.1 432.08,7779.4 432.64,7770.4 433.19,7761.4"];
	n49	 [height=1.6303,
		label="Node49\ninput = {torch.CudaTensor[1x128x4x4]}\lmodule = cudnn.ReLU\lreverseMap = {}\lgradOutput = {torch.CudaTensor[1x128x4x4]}",
		pos="983,8485",
		tooltip="[[C]]:-1_",
		width=5.3952];
	n49 -> n46	 [pos="e,983,8389.7 983,8426.1 983,8417.5 983,8408.7 983,8399.9"];
	n50	 [height=1.6303,
		label="Node50\ninput = {torch.CudaTensor[1x1024x8x8]}\lmodule = cudnn.ReLU\lreverseMap = {}\lgradOutput = {torch.CudaTensor[1x1024x8x8]}",
		pos="429,3227",
		tooltip="[[C]]:-1_",
		width=5.5097];
	n50 -> n47	 [pos="e,424.66,3131.7 426.33,3168.1 425.94,3159.5 425.53,3150.7 425.13,3141.9"];
	n51 -> n48	 [pos="e,424.2,7905.7 421.81,7942.1 422.37,7933.5 422.96,7924.7 423.53,7915.9"];
	n52	 [height=1.6303,
		label="Node52\ninput = {torch.CudaTensor[1x128x4x4]}\lmodule = cudnn.SpatialBatchNormalization\lreverseMap = {}\lgradOutput = {torch.CudaTensor[\
1x128x4x4]}",
		pos="983,8650",
		tooltip="[[C]]:-1_",
		width=5.3952];
	n52 -> n49	 [pos="e,983,8543.7 983,8591.1 983,8579.1 983,8566.3 983,8554"];
	n53	 [height=1.9249,
		label="Node53\ninput = {torch.CudaTensor[1x512x8x8],torch.CudaTensor[1x512x8x8]}\lmapindex = {Node55,Node56}\lmodule = nn.JoinTable\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x1024x8x8]}",
		pos="433,3392",
		tooltip="[[C]]:-1_",
		width=8.0879];
	n53 -> n50	 [pos="e,430.42,3285.8 431.32,3322.3 431.1,3313.6 430.88,3304.6 430.67,3295.9"];
	n54	 [height=1.6303,
		label="Node54\ninput = {torch.CudaTensor[1x64x2x2]}\lmodule = cudnn.SpatialFullConvolution(64 -> 128, 4x4, 2,2, 1,1)\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x128x4x4]}",
		pos="983,8815",
		tooltip="[[C]]:-1_",
		width=7.3969];
	n54 -> n52	 [pos="e,983,8708.7 983,8756.1 983,8744.1 983,8731.3 983,8719"];
	n55	 [height=1.6303,
		label="Node55\ninput = {torch.CudaTensor[1x512x8x8]}\lmodule = nn.Dropout(0.500000)\lreverseMap = {}\lgradOutput = {torch.CudaTensor[1x512x8x8]}",
		pos="440,3557",
		tooltip="[[C]]:-1_",
		width=5.3952];
	n55 -> n53	 [pos="e,435.93,3461.3 437.51,3498.1 437.14,3489.4 436.75,3480.4 436.37,3471.4"];
	n56	 [height=1.9249,
		label="Node56\ngradOutputBuffer = torch.CudaTensor[1x512x8x8]\linput = {torch.CudaTensor[1x512x8x8]}\lmodule = cudnn.SpatialBatchNormalization\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x512x8x8],torch.CudaTensor[1x512x8x8]}",
		pos="457,7198",
		tooltip="[[C]]:-1_",
		width=8.7551];
	n56 -> n53	 [pos="e,291.92,3452.7 317.06,7135.8 296.79,7123.2 277.31,7108.6 261,7092 186.72,7016.5 152,6985.9 152,6880 152,6880 152,6880 152,3710 \
152,3608.5 169.29,3573.6 237,3498 250.39,3483 266.42,3469.8 283.47,3458.3"];
	n71	 [height=1.6303,
		label="Node71\ninput = {torch.CudaTensor[1x512x8x8]}\lmodule = nn.LeakyReLU(0.2)\lreverseMap = {}\lgradOutput = {torch.CudaTensor[1x512x8x8]}",
		pos="464,7033",
		tooltip="[[C]]:-1_",
		width=5.3952];
	n56 -> n71	 [pos="e,461.52,7091.8 459.95,7128.3 460.32,7119.6 460.71,7110.6 461.08,7101.9"];
	n57	 [height=1.6303,
		label="Node57\ninput = {torch.CudaTensor[1x64x2x2]}\lmodule = cudnn.ReLU\lreverseMap = {}\lgradOutput = {torch.CudaTensor[1x64x2x2]}",
		pos="983,8969",
		tooltip="[[C]]:-1_",
		width=5.257];
	n57 -> n54	 [pos="e,983,8873.7 983,8910.1 983,8901.5 983,8892.7 983,8883.9"];
	n58	 [height=1.6303,
		label="Node58\ninput = {torch.CudaTensor[1x512x8x8]}\lmodule = cudnn.SpatialBatchNormalization\lreverseMap = {}\lgradOutput = {torch.CudaTensor[\
1x512x8x8]}",
		pos="453,3711",
		tooltip="[[C]]:-1_",
		width=5.3952];
	n58 -> n55	 [pos="e,444.94,3615.7 448.05,3652.1 447.32,3643.5 446.56,3634.7 445.81,3625.9"];
	n59	 [height=1.6303,
		label="Node59\ninput = {torch.CudaTensor[1x512x16x16]}\lmodule = cudnn.SpatialConvolution(512 -> 512, 4x4, 2,2, 1,1)\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x512x8x8]}",
		pos="450,7363",
		tooltip="[[C]]:-1_",
		width=7.0968];
	n59 -> n56	 [pos="e,454.07,7267.3 452.49,7304.1 452.86,7295.4 453.25,7286.4 453.63,7277.4"];
	n60	 [height=1.6303,
		label="Node60\ninput = {torch.CudaTensor[1x1x1x1]}\lmodule = cudnn.SpatialFullConvolution(1 -> 64, 4x4, 2,2, 1,1)\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x64x2x2]}",
		pos="982,9134",
		tooltip="[[C]]:-1_",
		width=7.1443];
	n60 -> n57	 [pos="e,982.65,9027.7 982.36,9075.1 982.43,9063.1 982.51,9050.3 982.58,9038"];
	n61	 [height=1.6303,
		label="Node61\ninput = {torch.CudaTensor[1x1024x4x4]}\lmodule = cudnn.SpatialFullConvolution(1024 -> 512, 4x4, 2,2, 1,1)\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x512x8x8]}",
		pos="460,3865",
		tooltip="[[C]]:-1_",
		width=7.6733];
	n61 -> n58	 [pos="e,455.66,3769.7 457.33,3806.1 456.94,3797.5 456.53,3788.7 456.13,3779.9"];
	n62 -> n59	 [pos="e,448.48,7421.7 447.52,7458.1 447.75,7449.5 447.98,7440.7 448.21,7431.9"];
	n63 -> n60	 [pos="e,982,9192.7 982,9240.1 982,9228.1 982,9215.3 982,9203"];
	n64	 [height=1.6303,
		label="Node64\ninput = {torch.CudaTensor[1x1024x4x4]}\lmodule = cudnn.ReLU\lreverseMap = {}\lgradOutput = {torch.CudaTensor[1x1024x4x4]}",
		pos="467,4019",
		tooltip="[[C]]:-1_",
		width=5.5097];
	n64 -> n61	 [pos="e,462.66,3923.7 464.33,3960.1 463.94,3951.5 463.53,3942.7 463.13,3933.9"];
	n65	 [height=1.9249,
		label="Node65\ninput = {torch.CudaTensor[1x512x4x4],torch.CudaTensor[1x512x4x4]}\lmapindex = {Node66,Node67}\lmodule = nn.JoinTable\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x1024x4x4]}",
		pos="471,4184",
		tooltip="[[C]]:-1_",
		width=8.0879];
	n65 -> n64	 [pos="e,468.42,4077.8 469.32,4114.3 469.1,4105.6 468.88,4096.6 468.67,4087.9"];
	n66	 [height=1.6303,
		label="Node66\ninput = {torch.CudaTensor[1x512x4x4]}\lmodule = nn.Dropout(0.500000)\lreverseMap = {}\lgradOutput = {torch.CudaTensor[1x512x4x4]}",
		pos="478,4349",
		tooltip="[[C]]:-1_",
		width=5.3952];
	n66 -> n65	 [pos="e,473.93,4253.3 475.51,4290.1 475.14,4281.4 474.75,4272.4 474.37,4263.4"];
	n67	 [height=1.9249,
		label="Node67\ngradOutputBuffer = torch.CudaTensor[1x512x4x4]\linput = {torch.CudaTensor[1x512x4x4]}\lmodule = cudnn.SpatialBatchNormalization\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x512x4x4],torch.CudaTensor[1x512x4x4]}",
		pos="495,6714",
		tooltip="[[C]]:-1_",
		width=8.7551];
	n67 -> n65	 [pos="e,329.92,4244.7 356.85,6651.7 336.69,6639.1 317.27,6624.5 301,6608 226.31,6532.3 190,6502.4 190,6396 190,6396 190,6396 190,4502 \
190,4400.5 207.29,4365.6 275,4290 288.39,4275 304.42,4261.8 321.47,4250.3"];
	n79	 [height=1.6303,
		label="Node79\ninput = {torch.CudaTensor[1x512x4x4]}\lmodule = nn.LeakyReLU(0.2)\lreverseMap = {}\lgradOutput = {torch.CudaTensor[1x512x4x4]}",
		pos="504,6549",
		tooltip="[[C]]:-1_",
		width=5.3952];
	n67 -> n79	 [pos="e,500.81,6607.8 498.79,6644.3 499.27,6635.6 499.77,6626.6 500.25,6617.9"];
	n68	 [height=1.6303,
		label="Node68\ninput = {torch.CudaTensor[1x512x4x4]}\lmodule = cudnn.SpatialBatchNormalization\lreverseMap = {}\lgradOutput = {torch.CudaTensor[\
1x512x4x4]}",
		pos="485,4503",
		tooltip="[[C]]:-1_",
		width=5.3952];
	n68 -> n66	 [pos="e,480.66,4407.7 482.33,4444.1 481.94,4435.5 481.53,4426.7 481.13,4417.9"];
	n69	 [height=1.6303,
		label="Node69\ninput = {torch.CudaTensor[1x512x8x8]}\lmodule = cudnn.SpatialConvolution(512 -> 512, 4x4, 2,2, 1,1)\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x512x4x4]}",
		pos="478,6879",
		tooltip="[[C]]:-1_",
		width=7.0968];
	n69 -> n67	 [pos="e,487.87,6783.3 484.04,6820.1 484.94,6811.4 485.88,6802.4 486.82,6793.4"];
	n70	 [height=1.6303,
		label="Node70\ninput = {torch.CudaTensor[1x1024x2x2]}\lmodule = cudnn.SpatialFullConvolution(1024 -> 512, 4x4, 2,2, 1,1)\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x512x4x4]}",
		pos="498,4657",
		tooltip="[[C]]:-1_",
		width=7.6733];
	n70 -> n68	 [pos="e,489.94,4561.7 493.05,4598.1 492.32,4589.5 491.56,4580.7 490.81,4571.9"];
	n71 -> n69	 [pos="e,472.68,6937.7 469.33,6974.1 470.12,6965.5 470.94,6956.7 471.75,6947.9"];
	n72	 [height=1.6303,
		label="Node72\ninput = {torch.CudaTensor[1x1024x2x2]}\lmodule = cudnn.ReLU\lreverseMap = {}\lgradOutput = {torch.CudaTensor[1x1024x2x2]}",
		pos="505,4811",
		tooltip="[[C]]:-1_",
		width=5.5097];
	n72 -> n70	 [pos="e,500.66,4715.7 502.33,4752.1 501.94,4743.5 501.53,4734.7 501.13,4725.9"];
	n73	 [height=1.9249,
		label="Node73\ninput = {torch.CudaTensor[1x512x2x2],torch.CudaTensor[1x512x2x2]}\lmapindex = {Node74,Node75}\lmodule = nn.JoinTable\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x1024x2x2]}",
		pos="509,4976",
		tooltip="[[C]]:-1_",
		width=8.0879];
	n73 -> n72	 [pos="e,506.42,4869.8 507.32,4906.3 507.1,4897.6 506.88,4888.6 506.67,4879.9"];
	n74	 [height=1.6303,
		label="Node74\ninput = {torch.CudaTensor[1x512x2x2]}\lmodule = nn.Dropout(0.500000)\lreverseMap = {}\lgradOutput = {torch.CudaTensor[1x512x2x2]}",
		pos="527,5141",
		tooltip="[[C]]:-1_",
		width=5.3952];
	n74 -> n73	 [pos="e,516.55,5045.3 520.6,5082.1 519.65,5073.4 518.65,5064.4 517.66,5055.4"];
	n75	 [height=1.9249,
		label="Node75\ngradOutputBuffer = torch.CudaTensor[1x512x2x2]\linput = {torch.CudaTensor[1x512x2x2]}\lmodule = cudnn.SpatialBatchNormalization\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x512x2x2],torch.CudaTensor[1x512x2x2]}",
		pos="533,6230",
		tooltip="[[C]]:-1_",
		width=8.7551];
	n75 -> n73	 [pos="e,370.01,5037.3 391.14,6167.9 373.07,6155.5 356.28,6140.9 343,6124 282.61,6047.2 285,6009.7 285,5912 285,5912 285,5912 285,5294 \
285,5198.2 268.47,5160.1 324,5082 334.38,5067.4 347.48,5054.6 361.88,5043.3"];
	n83	 [height=1.6303,
		label="Node83\ninput = {torch.CudaTensor[1x512x2x2]}\lmodule = nn.LeakyReLU(0.2)\lreverseMap = {}\lgradOutput = {torch.CudaTensor[1x512x2x2]}",
		pos="546,6065",
		tooltip="[[C]]:-1_",
		width=5.3952];
	n75 -> n83	 [pos="e,541.39,6123.8 538.48,6160.3 539.17,6151.6 539.89,6142.6 540.59,6133.9"];
	n76	 [height=1.6303,
		label="Node76\ninput = {torch.CudaTensor[1x512x2x2]}\lmodule = cudnn.SpatialBatchNormalization\lreverseMap = {}\lgradOutput = {torch.CudaTensor[\
1x512x2x2]}",
		pos="548,5295",
		tooltip="[[C]]:-1_",
		width=5.3952];
	n76 -> n74	 [pos="e,534.98,5199.7 540,5236.1 538.82,5227.5 537.59,5218.7 536.38,5209.9"];
	n77	 [height=1.6303,
		label="Node77\ninput = {torch.CudaTensor[1x512x4x4]}\lmodule = cudnn.SpatialConvolution(512 -> 512, 4x4, 2,2, 1,1)\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x512x2x2]}",
		pos="523,6395",
		tooltip="[[C]]:-1_",
		width=7.0968];
	n77 -> n75	 [pos="e,528.81,6299.3 526.55,6336.1 527.08,6327.4 527.64,6318.4 528.19,6309.4"];
	n78	 [height=1.6303,
		label="Node78\ninput = {torch.CudaTensor[1x512x1x1]}\lmodule = cudnn.SpatialFullConvolution(512 -> 512, 4x4, 2,2, 1,1)\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x512x2x2]}",
		pos="585,5449",
		tooltip="[[C]]:-1_",
		width=7.5351];
	n78 -> n76	 [pos="e,562.05,5353.7 570.91,5390.1 568.8,5381.4 566.61,5372.5 564.46,5363.6"];
	n79 -> n77	 [pos="e,515.78,6453.7 511.24,6490.1 512.31,6481.5 513.42,6472.7 514.51,6463.9"];
	n80	 [height=1.6303,
		label="Node80\ninput = {torch.CudaTensor[1x512x1x1]}\lmodule = cudnn.ReLU\lreverseMap = {}\lgradOutput = {torch.CudaTensor[1x512x1x1]}",
		pos="578,5603",
		tooltip="[[C]]:-1_",
		width=5.3952];
	n80 -> n78	 [pos="e,582.34,5507.7 580.67,5544.1 581.06,5535.5 581.47,5526.7 581.87,5517.9"];
	n81	 [height=1.6303,
		label="Node81\ninput = {torch.CudaTensor[1x512x1x1]}\lmodule = cudnn.SpatialBatchNormalization\lreverseMap = {}\lgradOutput = {torch.CudaTensor[\
1x512x1x1]}",
		pos="575,5757",
		tooltip="[[C]]:-1_",
		width=5.3952];
	n81 -> n80	 [pos="e,576.86,5661.7 576.14,5698.1 576.31,5689.5 576.49,5680.7 576.66,5671.9"];
	n82	 [height=1.6303,
		label="Node82\ninput = {torch.CudaTensor[1x512x2x2]}\lmodule = cudnn.SpatialConvolution(512 -> 512, 4x4, 2,2, 1,1)\lreverseMap = {}\lgradOutput = {\
torch.CudaTensor[1x512x1x1]}",
		pos="573,5911",
		tooltip="[[C]]:-1_",
		width=7.0968];
	n82 -> n81	 [pos="e,574.24,5815.7 573.76,5852.1 573.87,5843.5 573.99,5834.7 574.11,5825.9"];
	n83 -> n82	 [pos="e,562.74,5969.7 556.28,6006.1 557.82,5997.4 559.42,5988.5 560.99,5979.6"];
}
